{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] score: 80.00%\n"
     ]
    }
   ],
   "source": [
    "from imutils.perspective import four_point_transform\n",
    "from imutils import contours\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "# defining the answer key which maps the question number to the correct answer\n",
    "ANSWER_KEY = {0: 1, 1: 4, 2: 0, 3: 3, 4: 1}\n",
    "\n",
    "# loading the image, converting it to grayscale, blurring it slightly, then finding edges\n",
    "image = cv2.imread('test_01.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(blurred, 75, 200)\n",
    "\n",
    "# finding contours in the edge map, then initializing the contour that corresponds to the document\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "docCnt = None\n",
    "\n",
    "# ensuring that at least one contour was found\n",
    "if len(cnts) > 0:\n",
    "    # sorting the contours according to their size in descending order\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    # looping over the sorted contours\n",
    "    for c in cnts:\n",
    "        # approximating the contour\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "        # if our approximated contour has four points, then we can assume we have found the paper\n",
    "        if len(approx) == 4:\n",
    "            docCnt = approx\n",
    "            break\n",
    "\n",
    "# applying a four point perspective transformation to both the original image and grayscale image to obtain a \n",
    "# top-down birds eye view of the paper\n",
    "paper = four_point_transform(image, docCnt.reshape(4, 2))\n",
    "warped = four_point_transform(gray, docCnt.reshape(4, 2))\n",
    "\n",
    "# applying Otsu's thresholding method to binarize the warped piece of paper\n",
    "thresh = cv2.threshold(warped, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# finding contours in the thresholded image, then initializing the list of contours that correspond to questions\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "questionCnts = []\n",
    "\n",
    "# looping over the contours\n",
    "for c in cnts:\n",
    "    # computing the bounding box of the contour, then using the bounding box to derive the aspect ratio\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    ar = w / float(h)\n",
    "\n",
    "    # in order to label the contour as a question, region should be sufficiently wide, sufficiently tall,\n",
    "    # and have an aspect ratio approximately equal to 1\n",
    "    if w >= 20 and h >= 20 and ar >= 0.9 and ar <= 1.1:\n",
    "        questionCnts.append(c)\n",
    "\n",
    "# sorting the question contours top-to-bottom, then initializing the total number of correct answers\n",
    "questionCnts = contours.sort_contours(questionCnts,method=\"top-to-bottom\")[0]\n",
    "correct = 0\n",
    "\n",
    "# each question has 5 possible answers, to loop over the question in batches of 5\n",
    "for (q, i) in enumerate(np.arange(0, len(questionCnts), 5)):\n",
    "    # sorting the contours for the current question from left to right, then initializing the index of the\n",
    "    # bubbled answer\n",
    "    cnts = contours.sort_contours(questionCnts[i:i + 5])[0]\n",
    "    bubbled = None\n",
    "\n",
    "    # loop over the sorted contours\n",
    "    for (j, c) in enumerate(cnts):\n",
    "        # construct a mask that reveals only the current\n",
    "        # \"bubble\" for the question\n",
    "        mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "        cv2.drawContours(mask, [c], -1, 255, -1)\n",
    "\n",
    "        # apply the mask to the thresholded image, then\n",
    "        # count the number of non-zero pixels in the\n",
    "        # bubble area\n",
    "        mask = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "        total = cv2.countNonZero(mask)\n",
    "\n",
    "        # if the current total has a larger number of total\n",
    "        # non-zero pixels, then we are examining the currently\n",
    "        # bubbled-in answer\n",
    "        if bubbled is None or total > bubbled[0]:\n",
    "            bubbled = (total, j)\n",
    "\n",
    "    # initialize the contour color and the index of the\n",
    "    # *correct* answer\n",
    "    color = (0, 0, 255)\n",
    "    k = ANSWER_KEY[q]\n",
    "\n",
    "    # check to see if the bubbled answer is correct\n",
    "    if k == bubbled[1]:\n",
    "        color = (0, 255, 0)\n",
    "        correct += 1\n",
    "\n",
    "    # draw the outline of the correct answer on the test\n",
    "    cv2.drawContours(paper, [cnts[k]], -1, color, 3)\n",
    "\n",
    "# grab the test taker\n",
    "score = (correct / 5.0) * 100\n",
    "print(\"[INFO] score: {:.2f}%\".format(score))\n",
    "cv2.putText(paper, \"{:.2f}%\".format(score), (10, 30),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Exam\", paper)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optical Mark Recognition, hoặc OMR đơn giản là quá trình tự dộng phân tích tài liệu được con người tạo ra và  làm sáng tỏ kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils.perspective import four_point_transform\n",
    "from imutils import contours\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the answer key \n",
    "# which maps \n",
    "# the question number to the correct answer\n",
    "ANSWER_KEY = {0: 1, \n",
    "              1: 4, \n",
    "              2: 0, \n",
    "              3: 3, \n",
    "              4: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth=\"/home/anhp/Documents/coding/learnOpenCV/BubbleSheetScanner/Bubble-Sheet-Scanner/OMR Sheets/test_02.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xu ly anh dau vao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image, \n",
    "# convert it to grayscale, \n",
    "# blur it slightly, \n",
    "# then find edges\n",
    "image\t= cv2.imread(pth)                           # tai anh vao\n",
    "gray \t= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)   # chuyen doi sang gray\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)         # lam mo anh\n",
    "edged \t= cv2.Canny(blurred, 75, 200)               # tim canh cua doi tuong trong anh\n",
    "\n",
    "cv2.imshow(\"Image\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Lưu ý rằng cách các cạnh của tài liệu cần được xác định rõ ràng, \n",
    " với cả bốn đỉnh của ảnh _ bài trắc nghiệm scan_ \n",
    " \n",
    " Việc này rất quan trọng trong bước tiếp theo của chúng ta, \n",
    " vì chúng ta sẽ sử dụng nó như một điểm đánh dấu \n",
    " để kéo giãn và xóa hiệu ứng mắt chim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the edge map, \n",
    "# then initialize the contour \n",
    "# that corresponds to the document\n",
    "cnts = cv2.findContours(edged.copy(), \n",
    "                        cv2.RETR_EXTERNAL,\n",
    "\t\t\t\t\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "#cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "\n",
    "docCnt = None\n",
    "\n",
    "output = image.copy()  #-----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ensure that at least one contour was found\n",
    "if len(cnts) > 0:\n",
    "\t# sort the contours according to their size \n",
    " \t# in descending order\n",
    "\tcnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "\t\n",
    " \t# loop over the sorted contours\n",
    "  \t# ở mỗi contour chúng ta sẽ tìm các góc của contours sau khi approximated. \n",
    "\tfor c in cnts:\n",
    "\t\t# approximate the contour\n",
    "\t\tperi \t= cv2.arcLength(c, True)\n",
    "\t\tapprox \t= cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "  \n",
    "\t\t# if our approximated contour has four points,\n",
    "\t\t# then we can assume we have found the paper\n",
    "\t\tif len(approx) == 4:\n",
    "\t\t\tdocCnt = approx\n",
    "\t\t\tbreak\n",
    "\n",
    "   \n",
    "\tcv2.drawContours(output, [c], -1, (240, 0, 159), 3)\n",
    "\t#cv2.imshow(\"Contours\", output)\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sử dụng perspective transform để kéo giãn khung bài trắc nghiệm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Trong trường hợp này chúng ta sẽ sử dụng hàm four_point_transform  với chức năng là:\n",
    "\n",
    "    Xác định tọa độ (x, y)- contours với khả năng specific, reproducible manner.\n",
    "    Ap dụng perspective transform cho các vùng.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply a four point perspective transform \n",
    "# to both the original image and grayscale image \n",
    "# to obtain a top-down birds eye view of the paper\n",
    "paper \t= four_point_transform(image, docCnt.reshape(4, 2))\n",
    "\n",
    "#cv2.imshow(\"Paper\", paper)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warped \t= four_point_transform(gray, docCnt.reshape(4, 2))\n",
    "\n",
    "#cv2.imshow(\"Gray\", warped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "để đảm bảo ảnh không bị méo giống như ta dùng máy scan. \n",
    "\n",
    "Bước tiếp theo là chúng ta tiến hành nhị phân hóa ảnh :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply Otsu's thresholding method \n",
    "# to binarize the warped piece of paper\n",
    "thresh = cv2.threshold(warped, 0, 255,\n",
    "\t\t\t\t\t\tcv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#cv2.imshow(\"Thresh\", thresh)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ảnh được nhị phân này sẽ giúp chúng ta sử dụng phép tìm contour \n",
    " \n",
    " để tìm các khung tròn đáp án trên bài trắc nghiệm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the thresholded image, \n",
    "# then initialize the list of contours \n",
    "# that correspond to questions\n",
    "cnts = cv2.findContours(thresh.copy(), \n",
    "                        cv2.RETR_EXTERNAL,\n",
    "\t\t\t\t\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "questionCnts = []   # danh sách contours tương ứng với các câu hỏi,trả lời/khoanh tròn trên bài trắc nghiệm.\n",
    "\n",
    "paper2 = paper.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "khởi tạo questionCnts ,\n",
    "\n",
    "nó chính là danh sách contours \n",
    "\n",
    "tương ứng với các câu hỏi,trả lời/khoanh tròn trên bài trắc nghiệm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cần set điều kiện để kiểm tra xem contours đó có phải là vung tròn / câu trả lời của bài trắc nghiệm hay không:\n",
    "\n",
    "    Chiều rộng và cao phải thích hợp như ở trong ví dụ này sẽ là > 20 pixels .\n",
    "    Cần có tỉ lệ \"aspect ratio\"\" xấp xỉ = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the contours\n",
    "for ques in cnts:\n",
    "\t# compute the bounding box of the contour, \n",
    " \t# then use the bounding box to derive the aspect ratio\n",
    "\t(x, y, w, h) = cv2.boundingRect(ques)  # Với mỗi contours, chúng ta tính bounding box\n",
    "\tar = w / float(h)  \t\t\t\t\t# tỉ lệ của chiều rộng với chiều cao \n",
    " \n",
    "\t# in order to label the contour as a question, \n",
    " \t# region should be sufficiently wide, sufficiently tall, \n",
    "  \t# and\n",
    "\t# have an aspect ratio approximately equal to 1\n",
    "\tif w >= 20 and h >= 20 and ar >= 0.9 and ar <= 1.1:\n",
    "\t\tquestionCnts.append(ques)\n",
    "  \n",
    "\t\tcv2.drawContours(paper2, ques, -1, (0, 255, 255), 3)\n",
    "\t\t#cv2.imshow(\"Question\", paper2)\n",
    "\t\tcv2.waitKey(0)\n",
    "\t\t#cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the question contours top-to-bottom, \n",
    "# then initialize the total number of correct answers\n",
    "questionCnts = contours.sort_contours(\tquestionCnts,\n",
    "\t\t\t\t\t\t\t\t\t\tmethod=\"top-to-bottom\")[0]\n",
    "correct = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each question has 5 possible answers, \n",
    "# to loop over the question \n",
    "# in batches of 5\n",
    "for (q, i) in enumerate(np.arange(0, len(questionCnts), 5)):\n",
    "\t# sort the contours for the current question from\n",
    "\t# left to right, \n",
    " \t# then initialize the index of the\n",
    "\t# bubbled answer\n",
    "\tcnts = contours.sort_contours(questionCnts[i:i + 5])[0]\n",
    "\tbubbled = None\n",
    "\t#-------------------------------------------------------------------\n",
    " \n",
    " \n",
    "\t# loop over the sorted contours\n",
    "\t# Với mỗi hàng câu trả lời chúng ta tiến hành tìm kiếm các câu được trả lời bên trong ảnh.\n",
    "\tfor (j, c) in enumerate(cnts):\n",
    "\t\t# construct a mask that reveals only the current\n",
    "\t\t# \"bubble\" for the question\n",
    "\t\tmask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "\t\tcv2.drawContours(mask, [c], -1, 255, -1)\n",
    "\n",
    "\t\t# apply the mask to the thresholded image, then\n",
    "\t\t# count the number of non-zero pixels in the\n",
    "\t\t# bubble area\n",
    "\t\t# sử dụng ảnh thresh  và đếm số lượng điểm ảnh có giá trị = 0 trên mỗi vùng khoanh tròn.\n",
    "\t\tmask \t= cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "\t\ttotal \t= cv2.countNonZero(mask)\n",
    "\n",
    "\t\tcv2.imshow(\"ms\",mask)\n",
    "\t\tcv2.waitKey(0)\n",
    "\n",
    "\t\t# if the current total has a larger number of total\n",
    "\t\t# non-zero pixels, then we are examining the currently\n",
    "\t\t# bubbled-in answer\n",
    "\t\tif bubbled is None or total > bubbled[0]:\n",
    "\t\t\tbubbled = (total, j)\n",
    "\n",
    "\t\n",
    "\t# initialize the contour color and the index of the\n",
    "\t# *correct* answer\n",
    "\tcolor = (0, 0, 255)\n",
    "\tk = ANSWER_KEY[q]\n",
    "\n",
    "\t# check to see if the bubbled answer is correct\n",
    "\tif k == bubbled[1]:\n",
    "\t\tcolor = (0, 255, 0)\n",
    "\t\tcorrect += 1\n",
    "\t\n",
    "\t# draw the outline of the correct answer on the test\n",
    "\tcv2.drawContours(paper, [cnts[k]], -1, color, 3)\n",
    "\tcv2.imshow(\"Ex\",paper)\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the test taker\n",
    "score = (correct / 5.0) * 100\n",
    "print(\"[INFO] score: {:.2f}%\".format(score))\n",
    "\n",
    "cv2.putText(paper, \n",
    "            \"{:.2f}%\".format(score), \n",
    "            (10, 30),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, \n",
    "   \t\t\t0.9, (0, 0, 255), 2)\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Exam\", paper)\n",
    "\n",
    "cv2.imwrite(\"/home/anhp/Documents/coding/learnOpenCV/BubbleSheetScanner/exa/Exam1_1.png\", paper)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
